{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "BD7ucPsI9vUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "lyFIcOKu0-rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/chethuhn/network-intrusion-dataset/data\")"
      ],
      "metadata": {
        "id": "HgPkLTOm1AeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/network-intrusion-dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")"
      ],
      "metadata": {
        "id": "-p_5_R9A9ia0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "GRkB41tD-Aya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "6UDbChQx94fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.initializers import Constant"
      ],
      "metadata": {
        "id": "ooN8DT-l-EN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Describe Data"
      ],
      "metadata": {
        "id": "x-t8yzOx_ydi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include=['O'])"
      ],
      "metadata": {
        "id": "wN3waEPW-Cov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "0GnTLkrG-FWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "5PJqjF3o-Iq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[' Label'].unique()"
      ],
      "metadata": {
        "id": "C22NQDXRBuM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imputasi"
      ],
      "metadata": {
        "id": "IAjC84Hg_w1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengganti nilai inf dan -inf dengan NaN\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "wqEFaL9HAKJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputasi nilai hilang\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_numeric = df.select_dtypes(include=[np.number])\n",
        "X_numeric_imputed = pd.DataFrame(imputer.fit_transform(X_numeric), columns=X_numeric.columns)"
      ],
      "metadata": {
        "id": "ErWOgFiM_5Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengganti nilai hilang pada kolom kategorikal dengan modus\n",
        "X_categorical = df.select_dtypes(include=['object'])\n",
        "X_categorical_imputed = pd.DataFrame(imputer.set_params(strategy='most_frequent').fit_transform(X_categorical), columns=X_categorical.columns)"
      ],
      "metadata": {
        "id": "nkoNS4R7AWqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabungkan kembali kolom numerik dan kategorikal\n",
        "df_cleaned = pd.concat([X_numeric_imputed, X_categorical_imputed], axis=1)"
      ],
      "metadata": {
        "id": "yo4q0TBWA5E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding"
      ],
      "metadata": {
        "id": "NPon1UDqBIxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan encoding pada kolom target\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df[' Label'])"
      ],
      "metadata": {
        "id": "3pTY3QSeA_xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pisahkan fitur dan target\n",
        "X = df_cleaned.drop(' Label', axis=1)"
      ],
      "metadata": {
        "id": "rqh5UfjEBBtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalisasi"
      ],
      "metadata": {
        "id": "lx9hGU5dBL1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Normalisasi dengan Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)"
      ],
      "metadata": {
        "id": "elnUaNL7BN1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE"
      ],
      "metadata": {
        "id": "3z-9CTIzEjWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. SMOTE untuk menangani ketidakseimbangan kelas\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)"
      ],
      "metadata": {
        "id": "u5tn9JAr1-4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seleksi fitur"
      ],
      "metadata": {
        "id": "NKwluJWP2EnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Seleksi fitur (opsional)\n",
        "# Pilih 10 fitur terbaik berdasarkan ANOVA F-value\n",
        "selector = SelectKBest(score_func=f_classif, k=10)\n",
        "X_selected = pd.DataFrame(selector.fit_transform(X_resampled, y_resampled), columns=X_scaled.columns[selector.get_support()])"
      ],
      "metadata": {
        "id": "8y1xSoSC2Cu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset"
      ],
      "metadata": {
        "id": "K7svYF3i2Ima"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Split dataset menjadi data latih dan data uji\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_resampled, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "19X7biEI2McS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil akhir"
      ],
      "metadata": {
        "id": "tire4t7PEvhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hasil akhir\n",
        "print(\"Mapping label ke angka:\")\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "print(\"Distribusi target setelah SMOTE:\")\n",
        "print(pd.Series(y_resampled).value_counts())\n",
        "\n",
        "print(\"Dataset setelah preprocessing:\")\n",
        "print(X_train.head())"
      ],
      "metadata": {
        "id": "I8NzKR0mBa25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reshape data"
      ],
      "metadata": {
        "id": "iklajTidJ02v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ubah data menjadi bentuk 2D untuk CNN\n",
        "X_train_cnn = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_cnn = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "# Verifikasi bentuk data setelah reshaping\n",
        "print(X_train_cnn.shape)\n",
        "print(X_test_cnn.shape)"
      ],
      "metadata": {
        "id": "CRq0weMJXWmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "isbLpyrN3_Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membangun model dengan hyperparameter yang dapat disesuaikan\n",
        "def build_model(learning_rate=0.001, alpha=0.001, dropout_rate=0.3, bias_init_value=0.0, optimizer_choice='adam', input_shape=(100, 1)):\n",
        "    # Pilih optimizer berdasarkan input\n",
        "    if optimizer_choice == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_choice == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(\"Optimizer must be 'adam' or 'rmsprop'.\")\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer konvolusi pertama dengan regularisasi L2 dan bias initializer\n",
        "    model.add(Conv1D(filters=64,\n",
        "                     kernel_size=3,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=l2(alpha),\n",
        "                     input_shape=input_shape,\n",
        "                     bias_initializer=Constant(value=bias_init_value)))\n",
        "\n",
        "    # MaxPooling\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Layer konvolusi kedua\n",
        "    model.add(Conv1D(filters=128,\n",
        "                     kernel_size=3,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=l2(alpha),\n",
        "                     bias_initializer=Constant(value=bias_init_value)))\n",
        "\n",
        "    # MaxPooling\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Dropout layer untuk regularisasi\n",
        "    model.add(Dropout(rate=dropout_rate))\n",
        "\n",
        "    # Flatten layer untuk fully connected layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(units=128, activation='relu', kernel_regularizer=l2(alpha)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(units=2, activation='softmax'))  # Ganti sesuai jumlah kelas\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4hJkRFhNdSnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "e9XsEMGS4B8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train_cnn, y_train, epochs=100, batch_size=32, validation_data=None):\n",
        "    # Melatih model dengan data latih\n",
        "    history = model.fit(X_train_cnn, y_train, epochs=epochs, batch_size=batch_size, validation_data=validation_data)\n",
        "    return history"
      ],
      "metadata": {
        "id": "K_GhzYOHhuHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "9CYj80ro4E36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "sNrjNXp0TUFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(6,6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "def plot_roc_curve(y_test, y_pred_prob):\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "dRj8aMelbtvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test_cnn, y_test):\n",
        "    test_loss, test_acc = model.evaluate(X_test_cnn, y_test)\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    print(f\"Test loss: {test_loss}\")\n",
        "\n",
        "    y_pred = model.predict(X_test_cnn)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    precision = precision_score(y_test, y_pred_classes)\n",
        "    recall = recall_score(y_test, y_pred_classes)\n",
        "    f1 = f1_score(y_test, y_pred_classes)\n",
        "    auc_roc = roc_auc_score(y_test, y_pred[:, 1])\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred_classes)\n",
        "    plot_confusion_matrix(cm, class_names=['Class 0', 'Class 1'])\n",
        "    plot_roc_curve(y_test, y_pred[:, 1])\n",
        "\n",
        "    return test_acc, test_loss, precision, recall, f1, auc_roc"
      ],
      "metadata": {
        "id": "mJcFpm_oddoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "jqs8fGxM4LXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam Optimizer"
      ],
      "metadata": {
        "id": "85VEknUdBkDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_experiment_results(history, test_loss, test_acc):\n",
        "    # Mencetak hasil pelatihan (history)\n",
        "    print(\"\\nTraining History:\")\n",
        "    print(\"Epochs:\", len(history.history['loss']))\n",
        "    print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
        "    print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
        "\n",
        "    # Mencetak hasil evaluasi\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    print(f\"Test loss: {test_loss}\")\n",
        "\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"AUC-ROC: {auc_roc}\")"
      ],
      "metadata": {
        "id": "mt2qeOmodhLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_with_hyperparameters(learning_rate=0.001, alpha=0.001, dropout_rate=0.3, bias_init_value=0.0, optimizer_choice='adam', X_train_cnn=None, y_train=None, X_test_cnn=None, y_test=None):\n",
        "    # Bangun model dengan hyperparameter yang telah disesuaikan\n",
        "    model = build_model(learning_rate=learning_rate, alpha=alpha, dropout_rate=dropout_rate,\n",
        "                        bias_init_value=bias_init_value, optimizer_choice=optimizer_choice, input_shape=(X_train_cnn.shape[1], 1))\n",
        "\n",
        "    # Melatih model dengan data latih\n",
        "    history = train_model(model, X_train_cnn, y_train, epochs=3, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "    # Evaluasi model dengan data uji\n",
        "    test_loss, test_acc, precision, recall, f1, auc_roc = evaluate_model(model, X_test_cnn, y_test)\n",
        "\n",
        "    # Mencetak hasil eksperimen\n",
        "    print(f\"Experiment with learning_rate={learning_rate}, alpha={alpha}, dropout_rate={dropout_rate}, \"\n",
        "          f\"bias_init_value={bias_init_value}, optimizer={optimizer_choice}\")\n",
        "\n",
        "    # Menampilkan hasil eksperimen\n",
        "    print_experiment_results(history, test_loss, test_acc)"
      ],
      "metadata": {
        "id": "GqXcDdxghdbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "# Daftar jumlah hidden nodes dan learning rates untuk percobaan\n",
        "hidden_nodes_list = [20, 40, 60, 80, 100]\n",
        "learning_rates = [0.001, 0.005, 0.008]\n",
        "\n",
        "# List untuk menyimpan hasil percobaan\n",
        "results = []\n",
        "\n",
        "# Loop untuk semua kombinasi hidden nodes dan learning rates\n",
        "for hidden_nodes in hidden_nodes_list:\n",
        "    for lr in learning_rates:\n",
        "        print(f\"Testing with hidden nodes={hidden_nodes}, learning rate={lr}\")\n",
        "\n",
        "        # Fungsi untuk membangun model dengan jumlah hidden nodes tertentu\n",
        "        def build_model_with_hidden_nodes(hidden_units):\n",
        "            return build_model(learning_rate=lr, alpha=0.001, dropout_rate=0.3,\n",
        "                               bias_init_value=0.0, optimizer_choice='adam', input_shape=(X_train_cnn.shape[1], 1))\n",
        "\n",
        "        # Mulai pencatatan waktu\n",
        "        start_time = time()\n",
        "\n",
        "        # Bangun dan latih model\n",
        "        model = build_model_with_hidden_nodes(hidden_units=hidden_nodes)\n",
        "        history = train_model(model, X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "        # Hitung waktu training\n",
        "        elapsed_time = time() - start_time\n",
        "\n",
        "        # Ambil akurasi dari hasil training dan validasi\n",
        "        train_acc = history.history['accuracy'][-1]  # Akurasi terakhir pada training\n",
        "        val_acc = history.history['val_accuracy'][-1]  # Akurasi terakhir pada validasi\n",
        "\n",
        "        # Hitung akurasi pada data pengujian\n",
        "        test_loss, test_acc = model.evaluate(X_test_cnn, y_test, verbose=0)  # Evaluasi data pengujian\n",
        "\n",
        "        # Simpan hasil\n",
        "        results.append({\n",
        "            \"hidden_nodes\": hidden_nodes,\n",
        "            \"learning_rate\": lr,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"time\": elapsed_time\n",
        "        })\n",
        "\n",
        "# Cetak hasil percobaan dengan format tabel\n",
        "print(f\"\\n{'Hidden Nodes':<15}{'Learning Rate':<15}{'Train Accuracy':<15}{'Val Accuracy':<15}{'Test Accuracy':<15}{'Time (s)':<10}\")\n",
        "print(\"=\"*85)\n",
        "\n",
        "for result in results:\n",
        "    print(f\"{result['hidden_nodes']:<15}{result['learning_rate']:<15}{result['train_acc']:<15.4f}{result['val_acc']:<15.4f}{result['test_acc']:<15.4f}{result['time']:<10.2f}\")"
      ],
      "metadata": {
        "id": "8S27OV3we8sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix, Accuracy, Precision, Recall, F1-Score, and AUC-ROC"
      ],
      "metadata": {
        "id": "9kDdPxsYBY7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Gunakan parameter terbaik yang telah ditentukan\n",
        "best_learning_rate = 0.001\n",
        "best_hidden_nodes = 100\n",
        "\n",
        "# Bangun model dengan parameter terbaik\n",
        "best_model = build_model(learning_rate=best_learning_rate, alpha=0.001, dropout_rate=0.3,\n",
        "                        bias_init_value=0.0, optimizer_choice='adam', input_shape=(X_train_cnn.shape[1], 1))\n",
        "\n",
        "# Latih model dengan parameter terbaik\n",
        "history = train_model(best_model, X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "# Evaluasi model dengan data uji\n",
        "y_pred = best_model.predict(X_test_cnn)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "auc_roc = roc_auc_score(y_test, y_pred[:, 1])\n",
        "\n",
        "# Tampilkan confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Tampilkan ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Tampilkan hasil evaluasi\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"AUC-ROC: {auc_roc}\")"
      ],
      "metadata": {
        "id": "6s9fIwF9ymZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSprop Optimizer"
      ],
      "metadata": {
        "id": "I50kUOZnB_UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_experiment_results(history, test_loss, test_acc):\n",
        "    # Mencetak hasil pelatihan (history)\n",
        "    print(\"\\nTraining History:\")\n",
        "    print(\"Epochs:\", len(history.history['loss']))\n",
        "    print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
        "    print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
        "\n",
        "    # Mencetak hasil evaluasi\n",
        "    print(f\"Test accuracy: {test_acc}\")\n",
        "    print(f\"Test loss: {test_loss}\")\n",
        "\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1-Score: {f1}\")\n",
        "    print(f\"AUC-ROC: {auc_roc}\")"
      ],
      "metadata": {
        "id": "4JOq69fzCKlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_with_hyperparameters(learning_rate=0.001, alpha=0.001, dropout_rate=0.3, bias_init_value=0.0, optimizer_choice='rmsprop', X_train_cnn=None, y_train=None, X_test_cnn=None, y_test=None):\n",
        "    # Bangun model dengan hyperparameter yang telah disesuaikan\n",
        "    model = build_model(learning_rate=learning_rate, alpha=alpha, dropout_rate=dropout_rate,\n",
        "                        bias_init_value=bias_init_value, optimizer_choice=optimizer_choice, input_shape=(X_train_cnn.shape[1], 1))\n",
        "\n",
        "    # Melatih model dengan data latih\n",
        "    history = train_model(model, X_train_cnn, y_train, epochs=3, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "    # Evaluasi model dengan data uji\n",
        "    test_loss, test_acc, precision, recall, f1, auc_roc = evaluate_model(model, X_test_cnn, y_test)\n",
        "\n",
        "    # Mencetak hasil eksperimen\n",
        "    print(f\"Experiment with learning_rate={learning_rate}, alpha={alpha}, dropout_rate={dropout_rate}, \"\n",
        "          f\"bias_init_value={bias_init_value}, optimizer={optimizer_choice}\")\n",
        "\n",
        "    # Menampilkan hasil eksperimen\n",
        "    print_experiment_results(history, test_loss, test_acc)"
      ],
      "metadata": {
        "id": "r0_gIYztCKlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "# Daftar jumlah hidden nodes dan learning rates untuk percobaan\n",
        "hidden_nodes_list = [20, 40, 60, 80, 100]\n",
        "learning_rates = [0.001, 0.005, 0.008]\n",
        "\n",
        "# List untuk menyimpan hasil percobaan\n",
        "results = []\n",
        "\n",
        "# Loop untuk semua kombinasi hidden nodes dan learning rates\n",
        "for hidden_nodes in hidden_nodes_list:\n",
        "    for lr in learning_rates:\n",
        "        print(f\"Testing with hidden nodes={hidden_nodes}, learning rate={lr}\")\n",
        "\n",
        "        # Fungsi untuk membangun model dengan jumlah hidden nodes tertentu\n",
        "        def build_model_with_hidden_nodes(hidden_units):\n",
        "            return build_model(learning_rate=lr, alpha=0.001, dropout_rate=0.3,\n",
        "                               bias_init_value=0.0, optimizer_choice='rmsprop', input_shape=(X_train_cnn.shape[1], 1))\n",
        "\n",
        "        # Mulai pencatatan waktu\n",
        "        start_time = time()\n",
        "\n",
        "        # Bangun dan latih model\n",
        "        model = build_model_with_hidden_nodes(hidden_units=hidden_nodes)\n",
        "        history = train_model(model, X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "        # Hitung waktu training\n",
        "        elapsed_time = time() - start_time\n",
        "\n",
        "        # Ambil akurasi dari hasil training dan validasi\n",
        "        train_acc = history.history['accuracy'][-1]  # Akurasi terakhir pada training\n",
        "        val_acc = history.history['val_accuracy'][-1]  # Akurasi terakhir pada validasi\n",
        "\n",
        "        # Hitung akurasi pada data pengujian\n",
        "        test_loss, test_acc = model.evaluate(X_test_cnn, y_test, verbose=0)  # Evaluasi data pengujian\n",
        "\n",
        "        # Simpan hasil\n",
        "        results.append({\n",
        "            \"hidden_nodes\": hidden_nodes,\n",
        "            \"learning_rate\": lr,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_acc\": val_acc,\n",
        "            \"test_acc\": test_acc,\n",
        "            \"time\": elapsed_time\n",
        "        })\n",
        "\n",
        "# Cetak hasil percobaan dengan format tabel\n",
        "print(f\"\\n{'Hidden Nodes':<15}{'Learning Rate':<15}{'Train Accuracy':<15}{'Val Accuracy':<15}{'Test Accuracy':<15}{'Time (s)':<10}\")\n",
        "print(\"=\"*85)\n",
        "\n",
        "for result in results:\n",
        "    print(f\"{result['hidden_nodes']:<15}{result['learning_rate']:<15}{result['train_acc']:<15.4f}{result['val_acc']:<15.4f}{result['test_acc']:<15.4f}{result['time']:<10.2f}\")"
      ],
      "metadata": {
        "id": "gcIHC1pnCKlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix, Accuracy, Precision, Recall, F1-Score, and AUC-ROC"
      ],
      "metadata": {
        "id": "FP-zPuI7CKlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Gunakan parameter terbaik yang telah ditentukan\n",
        "best_learning_rate = 0.001\n",
        "best_hidden_nodes = 100\n",
        "\n",
        "# Bangun model dengan parameter terbaik\n",
        "best_model = build_model(learning_rate=best_learning_rate, alpha=0.001, dropout_rate=0.3,\n",
        "                        bias_init_value=0.0, optimizer_choice='rmsprop', input_shape=(X_train_cnn.shape[1], 1))\n",
        "\n",
        "# Latih model dengan parameter terbaik\n",
        "history = train_model(best_model, X_train_cnn, y_train, epochs=50, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "# Evaluasi model dengan data uji\n",
        "y_pred = best_model.predict(X_test_cnn)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes)\n",
        "recall = recall_score(y_test, y_pred_classes)\n",
        "f1 = f1_score(y_test, y_pred_classes)\n",
        "auc_roc = roc_auc_score(y_test, y_pred[:, 1])\n",
        "\n",
        "# Tampilkan confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_classes)\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Tampilkan ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Tampilkan hasil evaluasi\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n",
        "print(f\"AUC-ROC: {auc_roc}\")"
      ],
      "metadata": {
        "id": "Htna9H0fCKlT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}